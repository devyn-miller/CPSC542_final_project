{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, UpSampling2D, Input\n",
    "from keras.models import Sequential, Model\n",
    "# from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "vggmodel = VGG16()\n",
    "newmodel = Sequential() \n",
    "#num = 0\n",
    "for i, layer in enumerate(vggmodel.layers):\n",
    "    if i<19:          #Only up to 19th layer to include feature extraction only\n",
    "      newmodel.add(layer)\n",
    "newmodel.summary()\n",
    "for layer in newmodel.layers:\n",
    "  layer.trainable=False   #don't want to train these layers again, so False. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'images/colorization/'\n",
    "#Normalize images - divide by 255\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train = train_datagen.flow_from_directory(path, target_size=(224, 224), batch_size=32, class_mode=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same', input_shape=(7,7,512)))\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: BW image, Y: AB Channels\n",
    "X =[]\n",
    "Y =[]\n",
    "for img in train[0]:\n",
    "  try:\n",
    "      lab = rgb2lab(img)\n",
    "      X.append(lab[:,:,0]) \n",
    "      Y.append(lab[:,:,1:] / 128) #A and B values range from -127 to 128, \n",
    "      #so we divide the values by 128 to restrict values to between -1 and 1.\n",
    "  except:\n",
    "     print('error')\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X = X.reshape(X.shape+(1,)) #dimensions to be the same for X and Y\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one channel of L in each layer but, VGG16 is expecting 3 dimension, \n",
    "#so repeat the L channel two times to get 3 dimensions of the same L channel\n",
    "\n",
    "vggfeatures = []\n",
    "for i, sample in enumerate(X):\n",
    "  sample = gray2rgb(sample)\n",
    "  sample = sample.reshape((1,224,224,3))\n",
    "  prediction = newmodel.predict(sample)\n",
    "  prediction = prediction.reshape((7,7,512))\n",
    "  vggfeatures.append(prediction)\n",
    "vggfeatures = np.array(vggfeatures)\n",
    "print(vggfeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='mse' , metrics=['accuracy'])\n",
    "model.fit(vggfeatures, Y, verbose=1, epochs=10, batch_size=128)\n",
    "model.save('colorize_autoencoder_VGG16.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting using saved model.\n",
    "model = tf.keras.models.load_model('colorize_autoencoder_VGG16.model',\n",
    "                                   custom_objects=None,\n",
    "                                   compile=True)\n",
    "testpath = 'images/colorization2/test_images/'\n",
    "files = os.listdir(testpath)\n",
    "for idx, file in enumerate(files):\n",
    "    test = img_to_array(load_img(testpath+file))\n",
    "    test = resize(test, (224,224), anti_aliasing=True)\n",
    "    test*= 1.0/255\n",
    "    lab = rgb2lab(test)\n",
    "    l = lab[:,:,0]\n",
    "    L = gray2rgb(l)\n",
    "    L = L.reshape((1,224,224,3))\n",
    "    #print(L.shape)\n",
    "    vggpred = newmodel.predict(L)\n",
    "    ab = model.predict(vggpred)\n",
    "    #print(ab.shape)\n",
    "    ab = ab*128\n",
    "    cur = np.zeros((224, 224, 3))\n",
    "    cur[:,:,0] = l\n",
    "    cur[:,:,1:] = ab\n",
    "    imsave('images/colorization2/vgg_result/result'+str(idx)+\".jpg\", lab2rgb(cur))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
